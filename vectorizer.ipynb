{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import random\n",
    "from base64 import b64decode\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from urllib.parse import unquote\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = []\n",
    "with open('./db_notag_predict_noparse.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = json.loads(line)\n",
    "        line['label_tag'] = 'ATTACK' if len(line['tags'])>=2 else 'NORMAL'\n",
    "        line['label_extras'] = 'ATTACK' if len(line['extras'])>=2 else 'NORMAL'\n",
    "        line['label'] = 'ATTACK' if len(line['extras'])>=2 or len(line['tags'])>=2 else 'NORMAL'\n",
    "#         line.pop('tags')\n",
    "        data_pred.append(unquote(b64decode(line['raw']).decode('utf-8','ignore')))\n",
    "        if len(data_pred)==300000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = [{'ip':12,'text':'abc'},{'ip':23,'text':'sdf'},{'ip':34,'text':'dfd'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def count_ngram(document):\n",
    "#         document = self._white_spaces.sub(' ',document).lower()\n",
    "#         word_counter = {}\n",
    "#         for i in range(len(document)-ngram):\n",
    "#             w = document[i:i+ngram]\n",
    "#             if w in word_counter:\n",
    "#                 word_counter[w] += 1\n",
    "#             else:\n",
    "#                 word_counter[w] = 1\n",
    "#         w_end = document[-ngram:]\n",
    "#         return word_counter,w_end\n",
    "        return {'abc':1, 'bcd':2, 'def':3}\n",
    "\n",
    "class Vectorizer:\n",
    "    _white_spaces = re.compile(r\"\\s\\s+\")\n",
    "    def __init__(self,ngram_range = (1,1), tokenize_func = count_ngram):\n",
    "        self.min_gram,self.max_gram = ngram_range\n",
    "        self.tokenize_func = tokenize_func\n",
    "        self.vocab = {}\n",
    "\n",
    "    def group_by_ip(self,documents):\n",
    "        hosts = {}\n",
    "        for document in documents:\n",
    "            ip = document['ip']\n",
    "            tokens_counter = self.tokenize_func(document['text'])\n",
    "            if ip not in hosts:\n",
    "                hosts[ip] = {}\n",
    "            for token, count in tokens_counter.items():\n",
    "                if token in self.vocab:\n",
    "                    if token in hosts[ip]:\n",
    "                        hosts[ip][token][0] += 1\n",
    "                        hosts[ip][token][1] += count\n",
    "                    else:\n",
    "                        hosts[ip][token] = [1,count]\n",
    "        return hosts\n",
    "    \n",
    "    def get_stat_vocab(self,documents):\n",
    "        hosts = self.group_by_ip(documents)\n",
    "        stat_vocab = {}\n",
    "        for ip,tokens in hosts.items():\n",
    "            for token,count in tokens.items():\n",
    "                if token not in stat_vocab:\n",
    "                    stat_vocab[token] = [0,0]\n",
    "                stat_vocab[token][0] += 1\n",
    "                stat_vocab[token][1] += count[0]\n",
    "        return stat_vocab\n",
    "    \n",
    "    def build_vocab(self,documents):\n",
    "        vocab = {}\n",
    "        for document in documents:\n",
    "            tokens_counter = self.tokenize_func(document)\n",
    "            for token in tokens_counter:\n",
    "                if token in vocab:\n",
    "                    vocab[token] += 1\n",
    "                else:\n",
    "                    vocab[token] = 1\n",
    "        self.vocab = vocab\n",
    "        self.stat_vocab = self.get_stat_vocab(documents)\n",
    "#         return self.vocab, self.stat_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ip': 12, 'text': 'abc'}, {'ip': 23, 'text': 'sdf'}, {'ip': 34, 'text': 'dfd'}]\n"
     ]
    }
   ],
   "source": [
    "print(data_pred[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = Vectorizer(ngram_range = (2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.build_vocab(documents=data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': 3, 'bcd': 3, 'def': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abc': [3, 3], 'bcd': [3, 3], 'def': [3, 3]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.stat_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
